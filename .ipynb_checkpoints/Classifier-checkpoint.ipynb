{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Library for language detection</h2>\n",
    "\n",
    "*`By Fábio Bif Goularte`\n",
    "(fabio.goularte@gmail.com)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import modules</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Detecting the language</h4>\n",
    "\n",
    "Set the language of the document to detecting (line in[6]) with a code from the table below (column Language code).\n",
    "\n",
    "| Language | Language code | Language | Language code |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Afrikaans | af | Italian | it |\n",
    "| German | de | Japanese | ja |\n",
    "| English | en | Korean | ko |\n",
    "| Spanish | es | Portuguese (Brazil) | pt-BR |\n",
    "| Hindi | hi |  Chinese, Mandarin (Simplified) | zh-Hans |\n",
    "\n",
    "`Note:` It is possible to check other languages from those listed in the table above. Thus, provide a document in the desired language and run the Training Testing file to create the test document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      freq_af n-gramas\n",
      "0        1686        e\n",
      "1         795        n\n",
      "10        371        g\n",
      "100        19       pe\n",
      "1000        1      els\n",
      "1001        1      atv\n",
      "1002        1      old\n",
      "1003        1      oen\n",
      "1004        1      dei\n",
      "1005        1      svi\n",
      "1006        1      dhe\n",
      "1007        1      idw\n",
      "1008        1      ynv\n",
      "1009        1      yde\n",
      "101        19       ne\n",
      "1010        1      tir\n",
      "1011        1      vid\n",
      "1012        1      iei\n",
      "1013        1      skl\n",
      "1014        1      uis\n",
      "1015        1      med\n",
      "1016        1      ldt\n",
      "1017        1      e‐o\n",
      "1018        1      fbu\n",
      "1019        1      ‐eg\n",
      "102        19      and\n",
      "1020        1      onl\n",
      "1021        1      iko\n",
      "1022        1      pme\n",
      "1023        1      ikb\n",
      "...       ...      ...\n",
      "972         1      kom\n",
      "973         1      sed\n",
      "974         1      syn\n",
      "975         1      ’nd\n",
      "976         1      sse\n",
      "977         1      sra\n",
      "978         1      amh\n",
      "979         1      ‐sa\n",
      "98         19       nt\n",
      "980         1      wed\n",
      "981         1      apo\n",
      "982         1      ude\n",
      "983         1      mof\n",
      "984         1      ’nt\n",
      "985         1      rta\n",
      "986         1      anl\n",
      "987         1      ns‐\n",
      "988         1      ety\n",
      "989         1      keo\n",
      "99         19       ek\n",
      "990         1      esy\n",
      "991         1      moe\n",
      "992         1      psp\n",
      "993         1      sor\n",
      "994         1      pal\n",
      "995         1      syb\n",
      "996         1      inn\n",
      "997         1      kth\n",
      "998         1      rga\n",
      "999         1      ids\n",
      "\n",
      "[1366 rows x 2 columns]\n",
      "      freq_de n-gramas\n",
      "0        1751        e\n",
      "1        1067        n\n",
      "10        410        l\n",
      "100        21       uf\n",
      "1000        1      ewä\n",
      "1001        1      hlt\n",
      "1002        1      evö\n",
      "1003        1      rmi\n",
      "1004        1      fgl\n",
      "1005        1      zuö\n",
      "1006        1      edl\n",
      "1007        1      lem\n",
      "1008        1       av\n",
      "1009        1      fan\n",
      "101        21      gen\n",
      "1010        1      lth\n",
      "1011        1      erc\n",
      "1012        1      eke\n",
      "1013        1      gsf\n",
      "1014        1      gsä\n",
      "1015        1      ßtd\n",
      "1016        1      nme\n",
      "1017        1      inu\n",
      "1018        1      anz\n",
      "1019        1      uhä\n",
      "102        21      rec\n",
      "1020        1      ßen\n",
      "1021        1      höc\n",
      "1022        1      hst\n",
      "1023        1      fgr\n",
      "...       ...      ...\n",
      "972         1      dst\n",
      "973         1      owo\n",
      "974         1      ina\n",
      "975         1      lig\n",
      "976         1      lsa\n",
      "977         1      ftm\n",
      "978         1      umi\n",
      "979         1      ntu\n",
      "98         22       eg\n",
      "980         1      msb\n",
      "981         1      ubt\n",
      "982         1      enm\n",
      "983         1      dre\n",
      "984         1      usü\n",
      "985         1      bun\n",
      "986         1      ggo\n",
      "987         1      ear\n",
      "988         1      reb\n",
      "989         1      esm\n",
      "99         21      ech\n",
      "990         1      usc\n",
      "991         1      lke\n",
      "992         1      gez\n",
      "993         1      wun\n",
      "994         1       pö\n",
      "995         1      esl\n",
      "996         1      nmi\n",
      "997         1      dku\n",
      "998         1      lba\n",
      "999         1      hfr\n",
      "\n",
      "[1533 rows x 2 columns]\n",
      "      freq_en n-gramas\n",
      "0        1078        e\n",
      "1         803        t\n",
      "10        324        d\n",
      "100        20      tio\n",
      "1000        1      sio\n",
      "1001        1      sib\n",
      "1002        1      ene\n",
      "1003        1      lya\n",
      "1004        1      vai\n",
      "1005        1      hip\n",
      "1006        1      amo\n",
      "1007        1      atl\n",
      "1008        1      bef\n",
      "1009        1      ild\n",
      "101        19       ni\n",
      "1010        1      rbo\n",
      "1011        1      beg\n",
      "1012        1      kin\n",
      "1013        1      pri\n",
      "1014        1      vea\n",
      "1015        1      fpe\n",
      "1016        1      mai\n",
      "1017        1      ies\n",
      "1018        1      rni\n",
      "1019        1      edl\n",
      "102        19      ent\n",
      "1020        1      ert\n",
      "1021        1      lfu\n",
      "1022        1      psa\n",
      "1023        1      ock\n",
      "...       ...      ...\n",
      "972         1      fic\n",
      "973         1      plo\n",
      "974         1      gfr\n",
      "975         1      yme\n",
      "976         1      sul\n",
      "977         1      nts\n",
      "978         1      ndm\n",
      "979         1      eci\n",
      "98         20       rs\n",
      "980         1      ist\n",
      "981         1      anc\n",
      "982         1      hni\n",
      "983         1      rie\n",
      "984         1      ole\n",
      "985         1      ang\n",
      "986         1      yed\n",
      "987         1      bec\n",
      "988         1      orh\n",
      "989         1      omp\n",
      "99         20       fr\n",
      "990         1      gth\n",
      "991         1      uls\n",
      "992         1      hef\n",
      "993         1      fme\n",
      "994         1      irc\n",
      "995         1      cal\n",
      "996         1      bas\n",
      "997         1      oal\n",
      "998         1      let\n",
      "999         1      fes\n",
      "\n",
      "[1503 rows x 2 columns]\n",
      "      freq_es n-gramas\n",
      "0        1301        e\n",
      "1        1083        a\n",
      "10        474        t\n",
      "100        24       pe\n",
      "1000        1      ava\n",
      "1001        1      eél\n",
      "1002        1      ard\n",
      "1003        1      yap\n",
      "1004        1      ogr\n",
      "1005        1      ntí\n",
      "1006        1      sbe\n",
      "1007        1      nef\n",
      "1008        1      osq\n",
      "1009        1      ued\n",
      "101        24      ent\n",
      "1010        1      smo\n",
      "1011        1      anp\n",
      "1012        1      cor\n",
      "1013        1      sci\n",
      "1014        1      ífi\n",
      "1015        1      deq\n",
      "1016        1      eaa\n",
      "1017        1      uto\n",
      "1018        1      aqu\n",
      "1019        1      ezc\n",
      "102        23       at\n",
      "1020        1      goz\n",
      "1021        1      omu\n",
      "1022        1      dac\n",
      "1023        1      mar\n",
      "...       ...      ...\n",
      "972         1      ced\n",
      "973         1      oeq\n",
      "974         1      uiv\n",
      "975         1      gar\n",
      "976         1      ice\n",
      "977         1      see\n",
      "978         1      úbl\n",
      "979         1      rau\n",
      "98         25       su\n",
      "980         1      sed\n",
      "981         1      fir\n",
      "982         1      oap\n",
      "983         1      lgo\n",
      "984         1      rno\n",
      "985         1      ísd\n",
      "986         1      ire\n",
      "987         1      cta\n",
      "988         1      cog\n",
      "989         1      nee\n",
      "99         24      rec\n",
      "990         1      hod\n",
      "991         1      eac\n",
      "992         1      eig\n",
      "993         1      spú\n",
      "994         1      ísl\n",
      "995         1       ii\n",
      "996         1      sna\n",
      "997         1      esl\n",
      "998         1      uté\n",
      "999         1      esn\n",
      "\n",
      "[1502 rows x 2 columns]\n",
      "      freq_hi n-gramas\n",
      "0         875        ा\n",
      "1         744        ्\n",
      "10        275        व\n",
      "100        20       च्\n",
      "1000        2       तम\n",
      "1001        2      किव\n",
      "1002        2      कीर\n",
      "1003        2      ाजन\n",
      "1004        2       बद\n",
      "1005        2      ैति\n",
      "1006        2       णल\n",
      "1007        2       हस\n",
      "1008        2      थित\n",
      "1009        2       ोश\n",
      "101        20      मान\n",
      "1010        2      भेद\n",
      "1011        2      ंसे\n",
      "1012        2      सदस\n",
      "1013        2       २क\n",
      "1014        2      काव\n",
      "1015        2       मज़\n",
      "1016        2       तअ\n",
      "1017        2       ंल\n",
      "1018        2       दण\n",
      "1019        2      िचा\n",
      "102        20        घ\n",
      "1020        2       जक\n",
      "1021        2      रकि\n",
      "1022        2       िप\n",
      "1023        2       रग\n",
      "...       ...      ...\n",
      "972         2       छा\n",
      "973         2       बस\n",
      "974         2       शय\n",
      "975         2       हद\n",
      "976         2      ृष्\n",
      "977         2       रआ\n",
      "978         2       िऔ\n",
      "979         2       ोय\n",
      "98         21       ाह\n",
      "980         2       ीज\n",
      "981         2      पाठ\n",
      "982         2      ापू\n",
      "983         2       कज\n",
      "984         2      इसक\n",
      "985         2      या।\n",
      "986         2       ोऐ\n",
      "987         2       धह\n",
      "988         2       ेआ\n",
      "989         2       िख\n",
      "99         21       सा\n",
      "990         2       ोउ\n",
      "991         2       ेष\n",
      "992         2      िशे\n",
      "993         2       कभ\n",
      "994         2       कप\n",
      "995         2      रचा\n",
      "996         2       नर\n",
      "997         2      णाक\n",
      "998         2      ेंऔ\n",
      "999         2       धो\n",
      "\n",
      "[2342 rows x 2 columns]\n",
      "      freq_it n-gramas\n",
      "0        1439        i\n",
      "1        1222        e\n",
      "10        348        u\n",
      "100        26       uo\n",
      "1000        1      zar\n",
      "1001        1      zoe\n",
      "1002        1      mez\n",
      "1003        1      soo\n",
      "1004        1      noi\n",
      "1005        1      rin\n",
      "1006        1       àp\n",
      "1007        1      cip\n",
      "1008        1       uf\n",
      "1009        1      ull\n",
      "101        26       lo\n",
      "1010        1      ffo\n",
      "1011        1      cev\n",
      "1012        1       èp\n",
      "1013        1      ila\n",
      "1014        1      lli\n",
      "1015        1      àar\n",
      "1016        1      vef\n",
      "1017        1      rir\n",
      "1018        1      ofu\n",
      "1019        1      elm\n",
      "102        25       ea\n",
      "1020        1      tin\n",
      "1021        1      bin\n",
      "1022        1      bam\n",
      "1023        1      rad\n",
      "...       ...      ...\n",
      "972         1      mig\n",
      "973         1      ier\n",
      "974         1      afa\n",
      "975         1      gil\n",
      "976         1      tur\n",
      "977         1      ifu\n",
      "978         1      ens\n",
      "979         1      erv\n",
      "98         26       oc\n",
      "980         1       hé\n",
      "981         1       àh\n",
      "982         1      aop\n",
      "983         1      ipa\n",
      "984         1      tec\n",
      "985         1      iaz\n",
      "986         1      cra\n",
      "987         1      'as\n",
      "988         1       lg\n",
      "989         1      uòe\n",
      "99         26      lla\n",
      "990         1      nop\n",
      "991         1      fic\n",
      "992         1       gh\n",
      "993         1      àno\n",
      "994         1      riu\n",
      "995         1      ron\n",
      "996         1      oaf\n",
      "997         1      npo\n",
      "998         1      ard\n",
      "999         1      igu\n",
      "\n",
      "[1417 rows x 2 columns]\n",
      "      freq_ja n-gramas\n",
      "0         199        、\n",
      "1         189        の\n",
      "10         70        人\n",
      "100        10        基\n",
      "1000        1      て与え\n",
      "1001        1      とを決\n",
      "1002        1      向上と\n",
      "1003        1      人も、\n",
      "1004        1      ９条何\n",
      "1005        1      つ、一\n",
      "1006        1      な救済\n",
      "1007        1      、又は\n",
      "1008        1      な自由\n",
      "1009        1      効果的\n",
      "101         9      ること\n",
      "1010        1      のうち\n",
      "1011        1      で社会\n",
      "1012        1      裁判所\n",
      "1013        1      る国内\n",
      "1014        1      、権限\n",
      "1015        1      的進歩\n",
      "1016        1      と生活\n",
      "1017        1      水準の\n",
      "1018        1      侵害す\n",
      "1019        1      動しな\n",
      "102         9        き\n",
      "1020        1      別をそ\n",
      "1021        1      管轄上\n",
      "1022        1      うな差\n",
      "1023        1      れてお\n",
      "...       ...      ...\n",
      "972         1      又は残\n",
      "973         1      、拷問\n",
      "974         1      って促\n",
      "975         1      第５条\n",
      "976         1      言を公\n",
      "977         1      は、社\n",
      "978         1      連総会\n",
      "979         1      。人間\n",
      "98         10        際\n",
      "980         1      しても\n",
      "981         1      は法律\n",
      "982         1      治上、\n",
      "983         1      憲法又\n",
      "984         1      ８条す\n",
      "985         1      って行\n",
      "986         1      、平等\n",
      "987         1      神をも\n",
      "988         1      と協力\n",
      "989         1      為に対\n",
      "99         10       によ\n",
      "990         1      は、理\n",
      "991         1      なる行\n",
      "992         1      すいか\n",
      "993         1      人権及\n",
      "994         1      び基本\n",
      "995         1      そのか\n",
      "996         1      的自由\n",
      "997         1      の普遍\n",
      "998         1      的な尊\n",
      "999         1      意した\n",
      "\n",
      "[2504 rows x 2 columns]\n",
      "      freq_ko n-gramas\n",
      "0         100        의\n",
      "1          96        한\n",
      "10         66        자\n",
      "100        10      를가진\n",
      "1000        1      교육은\n",
      "1001        1      된대표\n",
      "1002        1      결사의\n",
      "1003        1      이선출\n",
      "1004        1      무적이\n",
      "1005        1      자유로\n",
      "1006        1      접또는\n",
      "1007        1      람은직\n",
      "1008        1      참여하\n",
      "1009        1      결사에\n",
      "101        10        언\n",
      "1010        1      도어떤\n",
      "1011        1      진다어\n",
      "1012        1      어야한\n",
      "1013        1      하고얻\n",
      "1014        1      집회및\n",
      "1015        1      화적인\n",
      "1016        1      람은평\n",
      "1017        1      포함한\n",
      "1018        1      자유를\n",
      "1019        1      달하는\n",
      "102        10      사람은\n",
      "1020        1      다기술\n",
      "1021        1      및직업\n",
      "1022        1      으며전\n",
      "1023        1      은사회\n",
      "...       ...      ...\n",
      "972         1      선거권\n",
      "973         1      ·평등\n",
      "974         1      이동일\n",
      "975         1      육은의\n",
      "976         1      여자국\n",
      "977         1      를통하\n",
      "978         1      야하며\n",
      "979         1      도정보\n",
      "98         10        합\n",
      "980         1      일반적\n",
      "981         1      으로접\n",
      "982         1      근이가\n",
      "983         1      통해서\n",
      "984         1      매체를\n",
      "985         1      계없이\n",
      "986         1      능하여\n",
      "987         1      경에관\n",
      "988         1      유와국\n",
      "989         1      을추구\n",
      "99         10       대한\n",
      "990         1      고등교\n",
      "991         1      가질자\n",
      "992         1      의견을\n",
      "993         1      섭없이\n",
      "994         1      리는간\n",
      "995         1      진다이\n",
      "996         1      에게실\n",
      "997         1      력에근\n",
      "998         1      거하여\n",
      "999         1      와사상\n",
      "\n",
      "[2140 rows x 2 columns]\n",
      "      freq_pt-BR n-gramas\n",
      "0           1181        e\n",
      "1            959        o\n",
      "10           364        u\n",
      "100           24      ade\n",
      "1000           1      sod\n",
      "1001           1      lap\n",
      "1002           1      rde\n",
      "1003           1      ied\n",
      "1004           1      mhi\n",
      "1005           1      toc\n",
      "1006           1      aer\n",
      "1007           1       úl\n",
      "1008           1      pót\n",
      "1009           1      mud\n",
      "101           24       rt\n",
      "1010           1      ouo\n",
      "1011           1      moc\n",
      "1012           1      iuv\n",
      "1013           1      em‐\n",
      "1014           1      dob\n",
      "1015           1      atê\n",
      "1016           1      mpú\n",
      "1017           1      ife\n",
      "1018           1      ice\n",
      "1019           1      sae\n",
      "102           23       io\n",
      "1020           1      gat\n",
      "1021           1      úde\n",
      "1022           1      mqu\n",
      "1023           1      por\n",
      "...          ...      ...\n",
      "972            1      oor\n",
      "973            1      irc\n",
      "974            1      dap\n",
      "975            1      adi\n",
      "976            1      epl\n",
      "977            1      luç\n",
      "978            1      tên\n",
      "979            1      ává\n",
      "98            24        z\n",
      "980            1      erq\n",
      "981            1      oli\n",
      "982            1      nhu\n",
      "983            1      exe\n",
      "984            1      alg\n",
      "985            1      óou\n",
      "986            1      asd\n",
      "987            1      dao\n",
      "988            1      amo\n",
      "989            1      ocu\n",
      "99            24       no\n",
      "990            1      lto\n",
      "991            1      emp\n",
      "992            1      icu\n",
      "993            1      eig\n",
      "994            1      emr\n",
      "995            1      pin\n",
      "996            1      nva\n",
      "997            1      çai\n",
      "998            1      god\n",
      "999            1      ênc\n",
      "\n",
      "[1544 rows x 2 columns]\n",
      "      freq_zh-Hans n-gramas\n",
      "0              149        的\n",
      "1              104        人\n",
      "10              33        条\n",
      "100              7        政\n",
      "1000             1      级和基\n",
      "1001             1      儿童无\n",
      "1002             1      少在初\n",
      "1003             1      免费至\n",
      "1004             1      育应当\n",
      "1005             1      权利教\n",
      "1006             1      都有受\n",
      "1007             1      十六条\n",
      "1008             1      会保护\n",
      "1009             1      样的社\n",
      "101              7        土\n",
      "1010             1      享受同\n",
      "1011             1      生都应\n",
      "1012             1      或非婚\n",
      "1013             1      论婚生\n",
      "1014             1      健康和\n",
      "1015             1      本人和\n",
      "1016             1      定他的\n",
      "1017             1      维持他\n",
      "1018             1      一个工\n",
      "1019             1      。㈢每\n",
      "102              7        领\n",
      "1020             1      工同酬\n",
      "1021             1      人有同\n",
      "1022             1      的保障\n",
      "1023             1      于失业\n",
      "...            ...      ...\n",
      "972              1      失业、\n",
      "973              1      在遭到\n",
      "974              1      会服务\n",
      "975              1      要的社\n",
      "976              1      疗和必\n",
      "977              1      房、医\n",
      "978              1      着、住\n",
      "979              1      物、衣\n",
      "98               7        治\n",
      "980              1      包括食\n",
      "981              1      活水准\n",
      "982              1      需的生\n",
      "983              1      福利所\n",
      "984              1      别照顾\n",
      "985              1      和协助\n",
      "986              1      。一切\n",
      "987              1      本阶段\n",
      "988              1      一切人\n",
      "989              1      绩而对\n",
      "99               7        鉴\n",
      "990              1      根据成\n",
      "991              1      。高等\n",
      "992              1      遍设立\n",
      "993              1      育应普\n",
      "994              1      职业教\n",
      "995              1      技术和\n",
      "996              1      性质。\n",
      "997              1      属义务\n",
      "998              1      。初级\n",
      "999              1      应如此\n",
      "\n",
      "[2368 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Code of language tested, e.g. 'pt-Br' to Portuguese\n",
    "languageDoc = 'pt-BR'\n",
    "\n",
    "#Load the n-gram model selected to test the language document (testing folder)\n",
    "df_test = pd.read_json('testing/'+languageDoc+'.json', orient='columns')\n",
    "df_test.columns=['n-gramas','freq_doc']\n",
    "\n",
    "languages = os.listdir('testing')\n",
    "\n",
    "#Load the n-grams models used to train the classifier according to the files in testing (training folder)\n",
    "for langTrain in languages:\n",
    "    langTrain  = langTrain.split('.')\n",
    "    df_train   = pd.read_json('training/'+langTrain[0]+'.json', orient='columns')\n",
    "    df_test    = df_test.merge(df_train,how='left',on='n-gramas')\n",
    "    print(df_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Shows the n-gram models based on the documents in the testing folder</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-gramas</th>\n",
       "      <th>freq_doc</th>\n",
       "      <th>freq_af</th>\n",
       "      <th>freq_de</th>\n",
       "      <th>freq_en</th>\n",
       "      <th>freq_es</th>\n",
       "      <th>freq_hi</th>\n",
       "      <th>freq_it</th>\n",
       "      <th>freq_ja</th>\n",
       "      <th>freq_ko</th>\n",
       "      <th>freq_pt-BR</th>\n",
       "      <th>freq_zh-Hans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>nos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n-gramas freq_doc  freq_af  freq_de  freq_en  freq_es  freq_hi  freq_it  \\\n",
       "0       445        a      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1       391        e      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2       150        t      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3         8        x      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4         1      nos      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   freq_ja  freq_ko  freq_pt-BR  freq_zh-Hans  \n",
       "0      NaN      NaN         NaN           NaN  \n",
       "1      NaN      NaN         NaN           NaN  \n",
       "2      NaN      NaN         NaN           NaN  \n",
       "3      NaN      NaN         NaN           NaN  \n",
       "4      NaN      NaN         NaN           NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new=df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>TF-IDF</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    651\u001b[0m             result = expressions.evaluate(op, str_rep, x, y,\n\u001b[0;32m--> 652\u001b[0;31m                                           raise_on_error=True, **eval_kwargs)\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, raise_on_error, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         return _evaluate(op, op_str, a, b, raise_on_error=raise_on_error,\n\u001b[0;32m--> 210\u001b[0;31m                          **eval_kwargs)\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b, raise_on_error, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, raise_on_error, **eval_kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0272286c4b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#Calculating TF-IDF per n-grams on the selected test document and on the documents from training folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcoll\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoll\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right, name, na_op)\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_na_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         return construct_result(\n\u001b[1;32m    717\u001b[0m             \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                     return _algos.arrmap_object(lvalues,\n\u001b[0;32m--> 686\u001b[0;31m                                                 lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\algos_common_helper.pxi\u001b[0m in \u001b[0;36mpandas.algos.arrmap_object (pandas\\algos.c:46681)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                     return _algos.arrmap_object(lvalues,\n\u001b[0;32m--> 686\u001b[0;31m                                                 lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "coll = list(df_test.columns) \n",
    "coll.pop(0)\n",
    "\n",
    "#Calculating TF-IDF per n-grams on the selected test document and on the documents from training folder\n",
    "for w in coll:\n",
    "    df_new[w]=df_test[w]/len(df_test)*np.log10(len(coll)/df_test.count(axis='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Function used to calculate the cosine similarity</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating cosine similarity\n",
    "def similarity(docA,docB):\n",
    "    numerator = 0\n",
    "    docA      = docA.replace(np.nan,0)\n",
    "    docB      = docB.replace(np.nan,0)\n",
    "    den_1     = math.sqrt(sum([docA[i]**2 for i in range(0,len(docA))]))\n",
    "    den_2     = math.sqrt(sum([docB[i]**2 for i in range(0,len(docB))]))\n",
    "    \n",
    "    for i in range(0,len(docA)): numerator=numerator+docA[i]*docB[i]\n",
    "    \n",
    "    denumerator = den_1*den_2\n",
    "    if denumerator == 0 : denumerator = 0.0001\n",
    "    \n",
    "    return numerator/denumerator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coll.pop(0)\n",
    "classifier = {}\n",
    "\n",
    "#Calculating the cosine similarity between 'languageDoc' and the other documents \n",
    "for w in coll:\n",
    "    classifier[w] = similarity(df_new['freq_doc'],df_new[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Shown the results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc tested: pt-BR\n",
      "\n",
      "Classification by similarity:\n",
      "freq_pt-BR: 0.9512008768057516\n",
      "freq_es: 0.9180541189217364\n",
      "freq_it: 0.8732348939396601\n",
      "freq_en: 0.8575734253085008\n",
      "freq_de: 0.7841373356480694\n",
      "freq_af: 0.7555665053842838\n",
      "freq_zh-Hans: 0.21549506976710367\n",
      "freq_hi: 0.0\n",
      "freq_ja: 0.0\n",
      "freq_ko: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Doc tested: '+languageDoc)\n",
    "print('\\nClassification by similarity:')\n",
    "\n",
    "for key, value in sorted(classifier.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(\"%s: %s\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
